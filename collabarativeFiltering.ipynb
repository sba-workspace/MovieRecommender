{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(\"movies.csv\")\n",
    "ratings=pd.read_csv(\"ratings.csv\")\n",
    "tags=pd.read_csv(\"tags.csv\")\n",
    "links=pd.read_csv(\"links.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944250228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>943230976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>944249077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>943228858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1       17     4.0  944249077\n",
       "1       1       25     1.0  944250228\n",
       "2       1       29     2.0  943230976\n",
       "3       1       30     5.0  944249077\n",
       "4       1       32     5.0  943228858"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Data for Reliability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users wiith 20 ratings\n",
    "user_ratings_counts=ratings.groupby(\"userId\").size()\n",
    "valid_users=user_ratings_counts[user_ratings_counts>=20].index\n",
    "ratings=ratings[ratings[\"userId\"].isin(valid_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies with 20 ratings\n",
    "movie_rating_counts=ratings.groupby(\"movieId\").size()\n",
    "valid_movies=movie_rating_counts[movie_rating_counts>=20].index\n",
    "ratings=ratings[ratings[\"movieId\"].isin(valid_movies)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Ratings Matrix (Y) and Indicator Matrix (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique movie and user ids from the filtered data\n",
    "\n",
    "unique_movie_ids=ratings[\"movieId\"].unique()\n",
    "unique_user_ids=ratings[\"userId\"].unique()\n",
    "\n",
    "num_movies=len(unique_movie_ids)\n",
    "num_users=len(unique_user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from movieId and userId to matrix indices\n",
    "\n",
    "movie_id_to_index={movie_id:i for i,movie_id in enumerate(unique_movie_ids)}\n",
    "\n",
    "user_id_to_index={user_id:i for i,user_id in enumerate(unique_user_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matrices: Y holds ratings, R indicates if a rating exists (1) or not (0)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Assuming ratings_df is your DataFrame with columns: userId, movieId, rating\n",
    "row_indices = ratings['movieId'].map(movie_id_to_index)\n",
    "col_indices = ratings['userId'].map(user_id_to_index)\n",
    "data = ratings['rating']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a sparse ratings matrix (COO format)\n",
    "Y_sparse = coo_matrix((data, (row_indices, col_indices)), shape=(num_movies, num_users))\n",
    "R_sparse = coo_matrix((np.ones_like(data), (row_indices, col_indices)), shape=(num_movies, num_users))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse ratings matrix shape: (23350, 200948)\n",
      "Number of non-zero entries in ratings: 31725920\n",
      "Sparse indicator matrix shape: (23350, 200948)\n",
      "Number of non-zero entries in indicator matrix: 31725920\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparse ratings matrix shape:\", Y_sparse.shape)\n",
    "print(\"Number of non-zero entries in ratings:\", Y_sparse.nnz)\n",
    "print(\"Sparse indicator matrix shape:\", R_sparse.shape)\n",
    "print(\"Number of non-zero entries in indicator matrix:\", R_sparse.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_csr = Y_sparse.tocsr()\n",
    "R_csr = R_sparse.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import dtype\n",
    "\n",
    "\n",
    "# def normalizeRatings_fromSparse(Y_csr,R_csr):\n",
    "#     m=Y_csr.shape[0]\n",
    "#     Ynorm=np.zeros((m,num_users), dtype=np.float32)\n",
    "#     Ymean = np.zeros((m, 1), dtype=np.float32)\n",
    "#     for i in range(m):\n",
    "#         # Get the dense row for movie i (only for indices with ratings)\n",
    "#         row_start = Y_csr.indptr[i]\n",
    "#         row_end   = Y_csr.indptr[i+1]\n",
    "#         if row_end > row_start:\n",
    "#             ratings = Y_csr.data[row_start:row_end]\n",
    "#             indices = Y_csr.indices[row_start:row_end]\n",
    "#             mean_rating = np.mean(ratings)\n",
    "#             Ymean[i] = mean_rating\n",
    "#             # Place normalized ratings in the corresponding columns\n",
    "#             Ynorm[i, indices] = ratings - mean_rating\n",
    "#     return Ynorm, Ymean\n",
    "# Ynorm, Ymean = normalizeRatings_fromSparse(Y_csr, R_csr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Ymean(Y_csr):\n",
    "    m = Y_csr.shape[0]\n",
    "    Ymean = np.zeros((m, 1), dtype=np.float32)\n",
    "    for i in range(m):\n",
    "        row = Y_csr.getrow(i)\n",
    "        if row.nnz > 0:\n",
    "            Ymean[i, 0] = np.mean(row.data)\n",
    "        else:\n",
    "            Ymean[i, 0] = 0.0\n",
    "    return Ymean\n",
    "\n",
    "Ymean = compute_Ymean(Y_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_row_generator():\n",
    "    \"\"\"\n",
    "    For each movie (row), yield:\n",
    "      - movie index (int)\n",
    "      - normalized ratings row (dense vector of shape (num_users,)), computed on the fly\n",
    "      - indicator row (dense vector of shape (num_users,))\n",
    "    \"\"\"\n",
    "    for i in range(num_movies):\n",
    "        # Get the sparse row for movie i\n",
    "        row = Y_csr.getrow(i)\n",
    "        # Build a dense normalized row on the fly:\n",
    "        # Allocate a dense vector of zeros for the full user dimension.\n",
    "        norm_row = np.zeros(num_users, dtype=np.float32)\n",
    "        if row.nnz > 0:\n",
    "            # Subtract the movie's mean from its nonzero ratings.\n",
    "            norm_row[row.indices] = row.data.astype(np.float32) - Ymean[i, 0]\n",
    "        # Get the corresponding indicator row from R\n",
    "        r_dense = R_csr.getrow(i).toarray().flatten().astype(np.float32)\n",
    "        yield i, norm_row, r_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sbari\\AppData\\Local\\Temp\\ipykernel_3848\\483286821.py:1: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\sbari\\AppData\\Local\\Temp\\ipykernel_3848\\483286821.py:1: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    movie_row_generator,\n",
    "    output_types=(tf.int32, tf.float32, tf.float32),\n",
    "    output_shapes=((), (num_users,), (num_users,))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 100  # latent feature dimension\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# X: movie features matrix, shape (num_movies, num_features)\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),stddev=0.01, dtype=tf.float32), name='X')\n",
    "# W: user features matrix, shape (num_users, num_features)\n",
    "W = tf.Variable(tf.random.normal((num_users, num_features),stddev=0.01, dtype=tf.float32), name='W')\n",
    "# b: user bias vector, shape (1, num_users)\n",
    "b = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float32), name='b')\n",
    "b_movies = tf.Variable(tf.zeros((num_movies, 1), dtype=tf.float32), name='b_movies')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_cost(X_batch, W, b, Y_batch, R_batch, lambda_):\n",
    "    # X_batch: (batch_size, num_features)\n",
    "    # Y_batch, R_batch: (batch_size, num_users)\n",
    "    predictions = tf.matmul(X_batch, W, transpose_b=True) + b  # (batch_size, num_users)\n",
    "    error = (predictions - Y_batch) * R_batch\n",
    "    cost = 0.5 * tf.reduce_sum(tf.square(error))\n",
    "    cost += (lambda_ / 2) * (tf.reduce_sum(tf.square(X_batch)) + tf.reduce_sum(tf.square(W))+tf.reduce_sum(tf.square(b_movies_batch)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch 10, Current cost: 862025.19\n",
      "  Batch 20, Current cost: 335439.75\n",
      "  Batch 30, Current cost: 192001.64\n",
      "  Batch 40, Current cost: 275550.91\n",
      "  Batch 50, Current cost: 106135.52\n",
      "  Batch 60, Current cost: 89548.34\n",
      "  Batch 70, Current cost: 30082.48\n",
      "  Batch 80, Current cost: 37282.74\n",
      "  Batch 90, Current cost: 38134.46\n",
      "  Batch 100, Current cost: 28241.84\n",
      "  Batch 110, Current cost: 18897.18\n",
      "  Batch 120, Current cost: 21920.80\n",
      "  Batch 130, Current cost: 11817.30\n",
      "  Batch 140, Current cost: 6582.86\n",
      "  Batch 150, Current cost: 9804.51\n",
      "  Batch 160, Current cost: 9217.42\n",
      "  Batch 170, Current cost: 9038.06\n",
      "  Batch 180, Current cost: 6815.80\n",
      "  Batch 190, Current cost: 4943.78\n",
      "  Batch 200, Current cost: 4771.76\n",
      "  Batch 210, Current cost: 4272.40\n",
      "  Batch 220, Current cost: 3324.58\n",
      "  Batch 230, Current cost: 2854.41\n",
      "Epoch 1/5 cost: 30324322.00\n",
      "  Batch 10, Current cost: 857115.06\n",
      "  Batch 20, Current cost: 333234.12\n",
      "  Batch 30, Current cost: 190416.80\n",
      "  Batch 40, Current cost: 273418.66\n",
      "  Batch 50, Current cost: 105201.62\n",
      "  Batch 60, Current cost: 88770.35\n",
      "  Batch 70, Current cost: 29761.43\n",
      "  Batch 80, Current cost: 36893.84\n",
      "  Batch 90, Current cost: 37737.61\n",
      "  Batch 100, Current cost: 27907.93\n",
      "  Batch 110, Current cost: 18696.70\n",
      "  Batch 120, Current cost: 21689.83\n",
      "  Batch 130, Current cost: 11670.80\n",
      "  Batch 140, Current cost: 6497.98\n",
      "  Batch 150, Current cost: 9692.14\n",
      "  Batch 160, Current cost: 9110.10\n",
      "  Batch 170, Current cost: 8941.72\n",
      "  Batch 180, Current cost: 6728.05\n",
      "  Batch 190, Current cost: 4889.97\n",
      "  Batch 200, Current cost: 4714.00\n",
      "  Batch 210, Current cost: 4220.61\n",
      "  Batch 220, Current cost: 3275.84\n",
      "  Batch 230, Current cost: 2815.16\n",
      "Epoch 2/5 cost: 30124668.00\n",
      "  Batch 10, Current cost: 851089.44\n",
      "  Batch 20, Current cost: 330638.16\n",
      "  Batch 30, Current cost: 188667.16\n",
      "  Batch 40, Current cost: 271105.25\n",
      "  Batch 50, Current cost: 104224.73\n",
      "  Batch 60, Current cost: 87965.77\n",
      "  Batch 70, Current cost: 29441.07\n",
      "  Batch 80, Current cost: 36504.67\n",
      "  Batch 90, Current cost: 37338.84\n",
      "  Batch 100, Current cost: 27576.88\n",
      "  Batch 110, Current cost: 18499.41\n",
      "  Batch 120, Current cost: 21460.25\n",
      "  Batch 130, Current cost: 11528.28\n",
      "  Batch 140, Current cost: 6416.86\n",
      "  Batch 150, Current cost: 9582.22\n",
      "  Batch 160, Current cost: 9005.35\n",
      "  Batch 170, Current cost: 8848.13\n",
      "  Batch 180, Current cost: 6643.23\n",
      "  Batch 190, Current cost: 4838.64\n",
      "  Batch 200, Current cost: 4658.59\n",
      "  Batch 210, Current cost: 4170.96\n",
      "  Batch 220, Current cost: 3229.54\n",
      "  Batch 230, Current cost: 2777.85\n",
      "Epoch 3/5 cost: 29894228.00\n",
      "  Batch 10, Current cost: 844671.38\n",
      "  Batch 20, Current cost: 327943.53\n",
      "  Batch 30, Current cost: 186853.91\n",
      "  Batch 40, Current cost: 268709.34\n",
      "  Batch 50, Current cost: 103234.99\n",
      "  Batch 60, Current cost: 87154.96\n",
      "  Batch 70, Current cost: 29123.17\n",
      "  Batch 80, Current cost: 36117.99\n",
      "  Batch 90, Current cost: 36941.57\n",
      "  Batch 100, Current cost: 27249.51\n",
      "  Batch 110, Current cost: 18304.57\n",
      "  Batch 120, Current cost: 21233.34\n",
      "  Batch 130, Current cost: 11388.70\n",
      "  Batch 140, Current cost: 6338.10\n",
      "  Batch 150, Current cost: 9474.43\n",
      "  Batch 160, Current cost: 8902.79\n",
      "  Batch 170, Current cost: 8756.64\n",
      "  Batch 180, Current cost: 6560.66\n",
      "  Batch 190, Current cost: 4788.97\n",
      "  Batch 200, Current cost: 4604.92\n",
      "  Batch 210, Current cost: 4122.94\n",
      "  Batch 220, Current cost: 3184.96\n",
      "  Batch 230, Current cost: 2741.96\n",
      "Epoch 4/5 cost: 29652428.00\n",
      "  Batch 10, Current cost: 837443.62\n",
      "  Batch 20, Current cost: 325111.56\n",
      "  Batch 30, Current cost: 184911.47\n",
      "  Batch 40, Current cost: 266140.31\n",
      "  Batch 50, Current cost: 102222.48\n",
      "  Batch 60, Current cost: 86333.41\n",
      "  Batch 70, Current cost: 28807.33\n",
      "  Batch 80, Current cost: 35732.98\n",
      "  Batch 90, Current cost: 36544.48\n",
      "  Batch 100, Current cost: 26925.47\n",
      "  Batch 110, Current cost: 18111.88\n",
      "  Batch 120, Current cost: 21009.17\n",
      "  Batch 130, Current cost: 11251.88\n",
      "  Batch 140, Current cost: 6261.48\n",
      "  Batch 150, Current cost: 9368.72\n",
      "  Batch 160, Current cost: 8802.34\n",
      "  Batch 170, Current cost: 8667.15\n",
      "  Batch 180, Current cost: 6480.24\n",
      "  Batch 190, Current cost: 4740.82\n",
      "  Batch 200, Current cost: 4552.93\n",
      "  Batch 210, Current cost: 4076.49\n",
      "  Batch 220, Current cost: 3142.00\n",
      "  Batch 230, Current cost: 2707.43\n",
      "Epoch 5/5 cost: 29385284.00\n"
     ]
    }
   ],
   "source": [
    "lambda_ = 0.01\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate,clipnorm=1.0)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_cost = 0.0\n",
    "    batch_count=0\n",
    "    for batch in dataset:\n",
    "        batch_count+=1\n",
    "        indices, Y_batch, R_batch = batch  # indices: (batch_size,), Y_batch, R_batch: (batch_size, num_users)\n",
    "        # Ensure that X is explicitly watched.\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(X)  # Ensure X is watched.\n",
    "            X_batch = tf.gather(X, indices)\n",
    "            cost_val = mini_batch_cost(X_batch, W, b, Y_batch, R_batch, lambda_)\n",
    "        # Compute gradients for X, W, and b in one go:\n",
    "        grad_X_full, grad_W, grad_b = tape.gradient(cost_val, [X, W, b])\n",
    "\n",
    "        \n",
    "        # Check if grad_X_full is still None (it shouldn't be now)\n",
    "        if grad_X_full is None:\n",
    "            raise ValueError(\"grad_X_full is None; check that your cost function depends on X.\")\n",
    "        \n",
    "        # Extract the gradient for the mini-batch slice.\n",
    "        grad_X_batch = tf.gather(grad_X_full, indices)\n",
    "        \n",
    "        # Update global parameters W and b using the optimizer.\n",
    "        optimizer.apply_gradients(zip([grad_W, grad_b], [W, b]))\n",
    "        \n",
    "        # Manually update the corresponding slice of X.\n",
    "        X_batch_updated = tf.gather(X, indices) - learning_rate * grad_X_batch\n",
    "        X.assign(tf.tensor_scatter_nd_update(X, tf.expand_dims(indices, 1), X_batch_updated))\n",
    "        \n",
    "        \n",
    "        epoch_cost += cost_val\n",
    "\n",
    "        if batch_count % 10 == 0:\n",
    "            print(f\"  Batch {batch_count}, Current cost: {cost_val.numpy():.2f}\")\n",
    "            if tf.math.is_nan(cost_val):\n",
    "                print(\"NaN detected! Stopping training.\")\n",
    "                break\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} cost: {epoch_cost.numpy():.2f}\")\n",
    "\n",
    "    if tf.math.is_nan(epoch_cost):\n",
    "        print(\"Training stopped due to NaN values\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
